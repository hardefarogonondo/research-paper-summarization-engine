{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20203c0f",
   "metadata": {},
   "source": [
    "# I. Project Team Members"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aa3d7f4",
   "metadata": {},
   "source": [
    "| Prepared by | Email | Prepared for |\n",
    "| :-: | :-: | :-: |\n",
    "| **Hardefa Rogonondo** | hardefarogonondo@gmail.com | **Research Paper Summarization Engine** |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b05cd469",
   "metadata": {},
   "source": [
    "# II. Notebook Target Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47bae1d2",
   "metadata": {},
   "source": [
    "_Insert Text Here_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3213f42d",
   "metadata": {},
   "source": [
    "# III. Notebook Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb5c3810",
   "metadata": {},
   "source": [
    "## III.A. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac84c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup, PegasusForConditionalGeneration, PegasusTokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017afc00-c0f2-4e73-9306-27fa00d492f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device name: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7291e85b",
   "metadata": {},
   "source": [
    "## III.B. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f425995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../../data/processed/train_df_processed.pkl')\n",
    "test_df= pd.read_pickle('../../data/processed/test_df_processed.pkl')\n",
    "validation_df = pd.read_pickle('../../data/processed/validation_df_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d849198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Due to the success of deep learning to solving...</td>\n",
       "      <td>We provide necessary and sufficient analytical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The backpropagation (BP) algorithm is often th...</td>\n",
       "      <td>Biologically plausible learning algorithms, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We introduce the 2-simplicial Transformer, an ...</td>\n",
       "      <td>We introduce the 2-simplicial Transformer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We present Tensor-Train RNN (TT-RNN), a novel ...</td>\n",
       "      <td>Accurate forecasting over very long time horiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recent efforts on combining deep models with p...</td>\n",
       "      <td>We propose a variational message-passing algor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Due to the success of deep learning to solving...   \n",
       "1  The backpropagation (BP) algorithm is often th...   \n",
       "2  We introduce the 2-simplicial Transformer, an ...   \n",
       "3  We present Tensor-Train RNN (TT-RNN), a novel ...   \n",
       "4  Recent efforts on combining deep models with p...   \n",
       "\n",
       "                                              target  \n",
       "0  We provide necessary and sufficient analytical...  \n",
       "1  Biologically plausible learning algorithms, pa...  \n",
       "2  We introduce the 2-simplicial Transformer and ...  \n",
       "3  Accurate forecasting over very long time horiz...  \n",
       "4  We propose a variational message-passing algor...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3fa463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Incremental class learning involves sequential...</td>\n",
       "      <td>FearNet is a memory efficient neural-network, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-view learning can provide self-supervisi...</td>\n",
       "      <td>Multi-view learning improves unsupervised sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We show how discrete objects can be learnt in ...</td>\n",
       "      <td>We show how discrete objects can be learnt in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most recent gains in visual recognition have o...</td>\n",
       "      <td>A large-scale dataset for training attention m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In recent years, deep neural networks have dem...</td>\n",
       "      <td>We proposed a time-efficient defense method ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Incremental class learning involves sequential...   \n",
       "1  Multi-view learning can provide self-supervisi...   \n",
       "2  We show how discrete objects can be learnt in ...   \n",
       "3  Most recent gains in visual recognition have o...   \n",
       "4  In recent years, deep neural networks have dem...   \n",
       "\n",
       "                                              target  \n",
       "0  FearNet is a memory efficient neural-network, ...  \n",
       "1  Multi-view learning improves unsupervised sent...  \n",
       "2  We show how discrete objects can be learnt in ...  \n",
       "3  A large-scale dataset for training attention m...  \n",
       "4  We proposed a time-efficient defense method ag...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1433f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mixed precision training (MPT) is becoming a p...</td>\n",
       "      <td>We devise adaptive loss scaling to improve mix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many real-world problems, e.g. object detectio...</td>\n",
       "      <td>We present a novel approach for learning to pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foveation is an important part of human vision...</td>\n",
       "      <td>We compare object recognition performance on i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We explore the concept of co-design in the con...</td>\n",
       "      <td>We develop methods to train deep neural models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batch Normalization (BatchNorm) has shown to b...</td>\n",
       "      <td>Investigation of how BatchNorm causes adversar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Mixed precision training (MPT) is becoming a p...   \n",
       "1  Many real-world problems, e.g. object detectio...   \n",
       "2  Foveation is an important part of human vision...   \n",
       "3  We explore the concept of co-design in the con...   \n",
       "4  Batch Normalization (BatchNorm) has shown to b...   \n",
       "\n",
       "                                              target  \n",
       "0  We devise adaptive loss scaling to improve mix...  \n",
       "1  We present a novel approach for learning to pr...  \n",
       "2  We compare object recognition performance on i...  \n",
       "3  We develop methods to train deep neural models...  \n",
       "4  Investigation of how BatchNorm causes adversar...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59e32c9",
   "metadata": {},
   "source": [
    "# IV. Models Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db0a5756",
   "metadata": {},
   "source": [
    "## IV.A. Data Shape Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad7798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1991, 2), (618, 2), (618, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, validation_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3389b1bf",
   "metadata": {},
   "source": [
    "## IV.B. Data Information Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d7319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1991 entries, 0 to 1991\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   source  1991 non-null   object\n",
      " 1   target  1991 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 46.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe621948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 618 entries, 0 to 617\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   source  618 non-null    object\n",
      " 1   target  618 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1aef8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 618 entries, 0 to 618\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   source  618 non-null    object\n",
      " 1   target  618 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.5+ KB\n"
     ]
    }
   ],
   "source": [
    "validation_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce34b86f",
   "metadata": {},
   "source": [
    "## IV.C. Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e911796-108d-4971-bb1a-d380a5d5c28d",
   "metadata": {},
   "source": [
    "### IV.C.1. Random Seed Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67a5248-bc1e-424e-813f-c2cc0de04327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=777):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "893bc015-9ad9-4be3-ab58-d50eec0abfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9eda58-6d11-44ae-b60b-0d6687ce1ce5",
   "metadata": {},
   "source": [
    "### IV.C.2. Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b65c84-5a93-4854-8bf9-23bd61a6b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text_list, summary_list, max_length=512):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for text, summary in zip(text_list, summary_list):\n",
    "            encodings = tokenizer(\n",
    "                text,\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            target_encodings = tokenizer(\n",
    "                summary,\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.input_ids.append(encodings.input_ids)\n",
    "            self.attn_masks.append(encodings.attention_mask)\n",
    "            self.labels.append(target_encodings.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx].flatten(),\n",
    "            \"attention_mask\": self.attn_masks[idx].flatten(),\n",
    "            \"labels\": self.labels[idx].flatten()\n",
    "        }\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "def prepare_data(tokenizer, dfs, batch_size=8):\n",
    "    datasets = {\n",
    "        split: SummarizationDataset(\n",
    "            tokenizer,\n",
    "            df[\"source\"].tolist(),\n",
    "            df[\"target\"].tolist()\n",
    "        ) for split, df in dfs.items()\n",
    "    }\n",
    "    loaders = {\n",
    "        f\"{split}_loader\": DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(split == \"train\")\n",
    "        ) for split, dataset in datasets.items()\n",
    "    }\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabcec1a-b058-4ad0-b83f-8416323c30ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small', legacy=False)\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b75e85c1-9e95-4338-914a-09cb1216fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    \"train\": train_df,\n",
    "    \"test\": test_df,\n",
    "    \"validation\": validation_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2562da98-f9e2-47ce-9a40-e904572294f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_loaders = prepare_data(t5_tokenizer, dataframes, batch_size=8)\n",
    "pegasus_loaders = prepare_data(pegasus_tokenizer, dataframes, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7533d-8ea0-42d2-baf6-94b0ec9633c7",
   "metadata": {},
   "source": [
    "### IV.C.3. Load Pre-Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "699ae07f-8987-4dd7-a88e-cbd167ec24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_and_optimizer(model_name, device, learning_rate, total_steps):\n",
    "    if model_name.startswith(\"t5\"):\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "    elif model_name.startswith(\"google/pegasus\"):\n",
    "        model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model. Please use 't5-small' or 'google/pegasus-xsum'.\")\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=total_steps)\n",
    "    return model, optimizer, scheduler\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, scheduler, device, data_loader, epochs=3):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "        average_train_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch {epoch+1} | Average Training Loss: {average_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513c5efa-cdc8-4063-b69d-a73d88c45f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f75fa-92f3-4634-8e21-a846114f2e82",
   "metadata": {},
   "source": [
    "### IV.C.4. T5 Small Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "731444df-1dea-4620-a3b2-bc51245fefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_model_name = 't5-small'\n",
    "# t5_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# t5_learning_rate = 5e-5\n",
    "# t5_total_steps = len(t5_loaders[\"train_loader\"]) * epochs\n",
    "# t5_batch_size = 8\n",
    "# t5_model, t5_optimizer, t5_scheduler = initialize_model_and_optimizer(t5_model_name, t5_device, t5_learning_rate, t5_total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e6772c-020a-4f35-b6f4-1489249bdcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(t5_model, t5_optimizer, t5_scheduler, t5_device, t5_loaders[\"train_loader\"], epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479a288-fa00-46c9-a1d6-ef5148c8a4cd",
   "metadata": {},
   "source": [
    "### IV.C.5. PEGASUS Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8827a1-d702-44d3-9e4f-21f02942fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pegasus_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pegasus_model_name = 'google/pegasus-xsum'\n",
    "pegasus_learning_rate = 5e-5\n",
    "pegasus_batch_size = 2\n",
    "pegasus_total_steps = len(pegasus_loaders[\"train_loader\"]) * epochs\n",
    "pegasus_model, pegasus_optimizer, pegasus_scheduler = initialize_model_and_optimizer(pegasus_model_name, pegasus_device, pegasus_learning_rate, pegasus_total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73ce1e0e-c3e8-4c9c-be45-843ce751315b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d589b2bbfea645438fc21b7a5274ea96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 752.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 19.79 GiB is allocated by PyTorch, and 232.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpegasus_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpegasus_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpegasus_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpegasus_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpegasus_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, scheduler, device, data_loader, epochs)\u001b[0m\n\u001b[0;32m     24\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pacmann_nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pacmann_nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pacmann_nlp\\Lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1375\u001b[0m, in \u001b[0;36mPegasusForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1354\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1355\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1356\u001b[0m         )\n\u001b[0;32m   1358\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1359\u001b[0m     input_ids,\n\u001b[0;32m   1360\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1373\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1374\u001b[0m )\n\u001b[1;32m-> 1375\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_logits_bias\u001b[49m\n\u001b[0;32m   1377\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 19.79 GiB is allocated by PyTorch, and 232.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "train_model(pegasus_model, pegasus_optimizer, pegasus_scheduler, pegasus_device, pegasus_loaders[\"train_loader\"], epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5f09b-6828-4eac-8b0a-757b1e13b3ef",
   "metadata": {},
   "source": [
    "## IV.D. Models Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f14d9-88d7-4ba6-b116-929db1b76c89",
   "metadata": {},
   "source": [
    "### IV.D.1. Baseline Model Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9c113-e755-4ad4-9eda-8a27463afd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summarization_model(model, model_name, tokenizer, data_loaders, device):\n",
    "    model.eval()\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    results = []\n",
    "    for key, data_loader in data_loaders.items():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pred_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            true_summaries = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "            rouge.add_batch(predictions=pred_summaries, references=true_summaries)\n",
    "        final_scores = rouge.compute()\n",
    "        result = {metric: value.mid.fmeasure * 100 for metric, value in final_scores.items()}\n",
    "        result[\"model\"] = model_name\n",
    "        result[\"dataset\"] = key\n",
    "        results.append(result)\n",
    "        rouge = load_metric(\"rouge\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa4c7b-ba67-48fe-82aa-33dbc975ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    \"train\": t5_loaders[\"train_loader\"],\n",
    "    \"validation\": t5_loaders[\"validation_loader\"],\n",
    "    \"test\": t5_loaders[\"test_loader\"]\n",
    "}\n",
    "\n",
    "df_t5 = evaluate_summarization_model(t5_model, \"T5\", t5_tokenizer, data_loaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672111a-4f04-4051-9f23-57b65a0f7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    \"train\": pegasus_loaders[\"train_loader\"],\n",
    "    \"validation\": pegasus_loaders[\"validation_loader\"],\n",
    "    \"test\": pegasus_loaders[\"test_loader\"]\n",
    "}\n",
    "\n",
    "df_t5 = evaluate_summarization_model(pegasus_model, \"T5\", pegasus_tokenizer, data_loaders, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bb2fc6d",
   "metadata": {},
   "source": [
    "### IV.E.3. Export Baseline Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../models/baseline_best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(baseline_best_model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de0ed9a4",
   "metadata": {},
   "source": [
    "## IV.F. Hyperparameters Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be189d67",
   "metadata": {},
   "source": [
    "### IV.F.1. Hyperparameters List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882ba16",
   "metadata": {},
   "source": [
    "#### IV.F.1.A. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7713f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_hyperparams = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5663b2-0c93-4dfb-b23d-79e98eac1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=777),\n",
    "    log_reg_hyperparams,\n",
    "    n_jobs=-1,\n",
    "    verbose=420,\n",
    "    scoring='f1_macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc81ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_from_grid = log_reg_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30add73-650f-41b2-848a-9f5e56568dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list[\"fine-tuned\"] = [{\"model_name\": \"GridSearchBest-LogisticRegression\",\n",
    "                              \"model_object\": best_estimator_from_grid, \"model_uid\": \"\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664aaa7f",
   "metadata": {},
   "source": [
    "#### IV.F.1.B. Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_space = {\n",
    "    'penalty': hyperopt.hp.choice('penalty', ['l1', 'l2']),\n",
    "    'C': hyperopt.hp.loguniform('C', np.log(1e-4), np.log(1e4)),\n",
    "    'solver': 'liblinear'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befcc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    classifier = LogisticRegression(**params, random_state=777)\n",
    "    score = cross_val_score(classifier, X_train,\n",
    "                            y_train, cv=5, scoring='f1_macro').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=log_reg_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "best_params = space_eval(log_reg_space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_log_reg = LogisticRegression(**best_params, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list[\"fine-tuned\"].append({\"model_name\": \"BayesOpt-LogisticRegression\",\n",
    "                                  \"model_object\": optimal_log_reg, \"model_uid\": \"\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7943a5bb",
   "metadata": {},
   "source": [
    "### IV.F.2. Best Model Hyperparameter Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log, models_list_tuned = model_training_and_evaluation(\n",
    "    models_list[\"fine-tuned\"],\n",
    "    \"tuned_model\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"tuned\",\n",
    "    '../../models/logs/training_log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c59ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc10a9-fdee-4c0b-951a-5ff793172a27",
   "metadata": {},
   "source": [
    "### IV.F.3. Hyperparameter-tuned Model Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f99ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_logs_df_tuned = training_log_to_df_converter(training_log)\n",
    "all_training_logs_df_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd33386",
   "metadata": {},
   "source": [
    "#### IV.F.3.A. Grid Searched Model Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict_tuned = {\"fine-tuned\": models_list_tuned}\n",
    "tuned_best_model = tuned_model_finder(\n",
    "    models_dict_tuned[\"fine-tuned\"], \"GridSearchBest\")\n",
    "tuned_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab61f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = get_metrics_dataframe(\n",
    "    tuned_best_model, X_train, y_train, X_test, y_test)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38be23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(\n",
    "    tuned_best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56320b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_vs_test_error(\n",
    "    tuned_best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(tuned_best_model, X_train,\n",
    "               y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e821a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_learning_curve(tuned_best_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c807ae",
   "metadata": {},
   "source": [
    "#### IV.F.3.B. Bayesian Searched Model Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict_tuned = {\"fine-tuned\": models_list_tuned}\n",
    "tuned_best_model = tuned_model_finder(\n",
    "    models_dict_tuned[\"fine-tuned\"], \"BayesOpt\")\n",
    "tuned_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = get_metrics_dataframe(\n",
    "    tuned_best_model, X_train, y_train, X_test, y_test)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(\n",
    "    tuned_best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_vs_test_error(\n",
    "    tuned_best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(tuned_best_model, X_train,\n",
    "               y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_learning_curve(tuned_best_model, X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44c44a6b",
   "metadata": {},
   "source": [
    "### IV.F.4. Export Hyperparameter-tuned Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../models/tuned_best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(tuned_best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
